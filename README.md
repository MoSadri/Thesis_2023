
‚≠êÔ∏è Research Project: Addressing Bias and Improving Transparency in Automated Hate Speech Detection Systems

This research project focuses on the paper titled "Automated Hate Speech Detection and the Problem of Offensive Language" by Thomas Davidson et al. Our primary objective is to investigate the impact of different group distributions on the performance of automated hate speech detection systems. We analyze the distribution of 11 distinct groups and assess how these distributions influence the effectiveness of hate speech detection.

Extension of Speech Classifier: This project builds upon the speech classifier program originally developed by Thomas Davidson et al. The original repository by Thomas Davidson (https://github.com/t-davidson/hate-speech-and-offensive-language) is no longer maintained. In response, we created our own version of the classifier, introduced modifications, and conducted testing with various datasets.

Dataset Testing: We tested our program using speech data provided by Berkeley (link), assessing its accuracy in hate speech detection.

Jupyter Notebook Training: The training process begins with a Jupyter Notebook program, "generate_trained_model.ipynb." This notebook generates five .pkl files, which contain the trained data necessary for executing the primary program, "speech_classifier.py." These .pkl files are integral to the functioning of the classifier.

üìÅ Project Structure:

‚úÖ Data Folder: Contains essential data files.

‚úÖ labeled_data.csv: This CSV file includes 24,784 rows, comprising tweets, group labels (hate, offensive, neither), and their respective counts.

‚úÖ training_dataset.csv: This CSV file contains 8,000 rows, which serve as the training data for our experiments.

‚úÖ Input Folder: Contains data used as input for analysis. These are the target groups whose distributions we are studying.

‚úÖ Output Folder: This folder is reserved for storing the results generated by running the program.

There are 6 files in the folder speech_classifier folder:

generate_group_csv.py
count_groups.py
generate_trained_model.ipynb
speech_classifier.py
generate_cv_data.py
run_cross_validation.py
All .py files can be run by the simple command such as: python program_name.py

1Ô∏è‚É£Program 1: generate_group_csv.py

This program, named generate_group_csv.py, reads speech data from the "data" folder provided by Berkeley. It allows you to select and analyze a specific number of groups from the data. You can experiment with different scenarios by adjusting the number of targeted groups in the file.

2Ô∏è‚É£Program 2: count_groups.py

The second program, count_groups.py, is a straightforward script. It calculates and displays the actual number of groups resulting from the first program's analysis. Since there can be overlaps among the targeted groups, it also provides the percentage of each group.

3Ô∏è‚É£Program 3: generate_trained_model.ipynb

The third program, generate_trained_model.ipynb, is a Jupyter Notebook script. It's designed to create a trained model required for the speech classifier program. This program generates five .pkl files that must be passed to speech_classifier.py for further processing.

4Ô∏è‚É£speech_classifier.py

The speech_classifier.py file houses the main speech classification program. It performs analysis on speech files located in the input folder and calculates the number of hate speech instances detected within those files. Additionally, it is configured to analyze a pre-labeled dataset called labeled_data.csv, which was curated by TDavidson for program testing purposes. This dataset aids in evaluating the program's accuracy, precision, recall, and F1 score to assess its performance.

Overall, steps to run the speech classifier:

python generate_group_csv.py
Run the generate_trained_model.ipynb in your preferred Jupyter Notebook interface.
python speech_classifier.py
There are two more files: generate_cv_data.py and run_cross_validation.py. These two files are used for performing k-fold cross-validation. Currently k is set to be 5, but users can set it to different numbers in order to perform k-fold cross-validation.

The steps are similar, first run the generate_group_csv.py to produce training data with the desired number for each targeted group, then generate the .pkl files, then run the actual cross-validation.

The steps are:

python generate_group_csv.py
python generate_cv_data.py
python run_cross_validation.py
